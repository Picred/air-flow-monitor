version: '3.8'

networks:
  aqm:
    name: aqm
    ipam:
      driver: default
      config:
        - subnet: 10.0.100.0/24

services:
  kafka_zk:
    build:
      context: kafka/
      dockerfile: Dockerfile
    container_name: kafkaZK
    environment:
      KAFKA_ACTION: start-zk
    networks:
      aqm:
        ipv4_address: 10.0.100.22
    ports:
      - "2181:2181"

  kafka_server:
    build:
      context: kafka/
      dockerfile: Dockerfile
    environment:
      - KAFKA_ACTION=start-kafka
    container_name: kafkaServer
    hostname: kafkaServer
    networks:
      aqm:
        ipv4_address: 10.0.100.23
    ports:
      - "9092:9092"

  kafka_ui:
    image: provectuslabs/kafka-ui:v0.7.2
    environment:
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=10.0.100.23:9092
      - KAFKA_CLUSTERS_0_ZOOKEEPER=10.0.100.22:2181
    container_name: kafkaUI
    networks:
      aqm:
    ports:
      - "8080:8080"

  logstash:
    image: docker.elastic.co/logstash/logstash:8.13.0
    hostname: logstash
    container_name: logstash
    volumes:
      - ./logstash/pipeline/from_python_to_kafka.conf:/usr/share/logstash/pipeline/logstash.conf
    environment:
      - XPACK_MONITORING_ENABLED=false
    networks:
      aqm:
  
  ingestion_manager:
    build:
      context: ingestion_manager
      dockerfile: Dockerfile
    hostname: ingestion_manager
    container_name: ingestion_manager
    depends_on:
      - logstash
      - spark
    networks:
      aqm:

  spark:
    image: apache/spark:3.5.1
    hostname: spark
    container_name: spark
    volumes:
      - ./spark/code/app.py:/opt/aqm/app.py
    command: > 
      /opt/spark/bin/spark-submit --conf spark.driver.extraJavaOptions="-Divy.cache.dir=/tmp -Divy.home=/tmp" --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1  /opt/aqm/app.py 
    networks:
      aqm:
    ports:
      - "4040:4040"